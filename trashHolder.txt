(Files content cropped to 300k characters, download full ingest to see more)
================================================
File: README.md
================================================
# Razvald Helicopter Project

## Описание проекта

Данный проект предназначен для калибровки, обработки и анализа данных с камер и датчиков дронов. Он включает в себя инструменты для работы с координатами, преобразованиями данных и профилирования системы.

---

## Структура репозитория

### Главные файлы и директории

- **[`Calibrate/`](./Calibrate/):** Основная директория для калибровки.
  - **[`calibrate.ipynb`](./Calibrate/calibrate.ipynb):** Jupyter Notebook для калибровки.
  - **[`calibrate.py`](./Calibrate/calibrate.py):** Скрипт для автоматизации калибровки.
  - **[`fisheye_2024-09-18.json`](./Calibrate/fisheye_2024-09-18.json):** Конфигурация камеры (параметры "рыбий глаз").
  - **[`vio_ort.py`](./Calibrate/vio_ort.py):** Модуль для обработки визуально-инерциальной одометрии (VIO).
  - **[`Debugs/`](./Calibrate/Debugs):** Логи и параметры отладки.
  - **[`Profiling/`](./Calibrate/Profiling):** Скрипты и отчёты для профилирования.

- **[`modules/`](./modules/):** Директория с основными библиотеками.
  - **[`interpolator.py`](./modules/interpolator.py):** Модуль для интерполяции данных.
  - **[`lighterglue.py`](./modules/lighterglue.py):** Легковесный алгоритм для склеивания данных.
  - **[`xfeat.py`](./modules/xfeat.py):** Обработка признаков.
  - **[`xfeat_ort.py`](./modules/xfeat_ort.py):** Обработка признаков с использованием оптимизированного метода (ORT).
  - **[`dataset/`](./modules/dataset):** Обработка данных для обучения.
  - **[`training/`](./modules/training):** Модули для обучения моделей.
  - **[`weights/`](./modules/weights):** Предобученные веса моделей.

- **[`Объяснение всего кода.md`](./Объяснение%20всего%20кода.md):** Подробное описание работы проекта.

---

## Основные возможности

1. **Калибровка камеры:**
   - Использование данных конфигурации камеры для коррекции искажений.
2. **Работа с VIO-координатами:**
   - Преобразование и синхронизация данных GPS и VIO.
3. **Анализ данных:**
   - Построение графиков и профилирование системы.
4. **Поддержка нейронных сетей:**
   - Работа с весами, обучением и предобученными моделями.

---

## Как использовать

### Установка

1. Клонируйте репозиторий:
   ```bash
   git clone <URL-репозитория>
   cd razvald-helicopter.git
   ```

2. Установите необходимые зависимости:
   ```bash
   pip install -r requirements.txt
   ```

### Основные скрипты

- Запустите **калибровку**:
  ```bash
  python Calibrate/calibrate.py
  ```

- Используйте **Jupyter Notebook** для анализа:
  ```bash
  jupyter notebook Calibrate/calibrate.ipynb
  ```

---

## Полезные ссылки

- [VIO обработка: `vio_ort.py`](./Calibrate/vio_ort.py)
- [Калибровка камеры: `calibrate.ipynb`](./Calibrate/calibrate.ipynb)
- [Подробное объяснение кода](./Объяснение%20всего%20кода.md)

================================================
File: trashHolder.txt
================================================
Объяснение всего кода.md
requirements.txt

================================================
File: Calibrate/calibrate.ipynb
================================================
# Jupyter notebook converted to Python script.

import nvtx
import vio_ort
import matplotlib.pyplot as plt
import os
import json
import cv2
import concurrent.futures
import threading
from collections import defaultdict
import plotly.graph_objects as go

odometry = vio_ort.VIO(lat0=54.889668, lon0=83.1258973333, alt0=0)

# Путь к папке
set_dir = '2024_12_15_15_31_8_num_3'

# Получение всех файлов с расширением .json
json_files = [f for f in os.listdir(set_dir) if f.endswith('.json')]

# Сортировка файлов по имени
json_files.sort()

start = 0
count_json = len(json_files)

lat_VIO = []
lon_VIO = []

lat_GPS = []
lon_GPS = []

alt_VIO = []
alt_GPS = []

# Инициализация структуры для ошибок
fails_collect = defaultdict(lambda: {'num': 0, 'files': []})

lock = threading.Lock()

@nvtx.annotate("Register Error", color="red")
def register_error(error_type, filename):
    with lock:
        if error_type not in fails_collect:
            fails_collect[error_type] = {'num': 0, 'files': []}
        fails_collect[error_type]['num'] += 1
        fails_collect[error_type]['files'].append(filename)

@nvtx.annotate("Process File", color="blue")
def process_file(filename):
    with nvtx.annotate("Load JSON", color="cyan"):
        try:
            with open(os.path.join(set_dir, filename), 'r') as file:
                data = json.load(file)
        except json.JSONDecodeError:
            register_error("JSON decode error", filename)
            return
        except Exception:
            register_error("Processing error", filename)
            return

    with nvtx.annotate("Validate Data", color="magenta"):
        if 'GNRMC' not in data or 'VIO' not in data:
            register_error("Missing GNRMC or VIO", filename)
            return

        if data['GNRMC'].get('status') != 'A':
            register_error("GNRMC status not 'A'", filename)
            return

    with nvtx.annotate("Load Image", color="yellow"):
        img_path = os.path.join(set_dir, os.path.splitext(filename)[0] + '.jpg')
        if not os.path.exists(img_path):
            register_error("Image not found", filename)
            return

        image = cv2.imread(img_path)
        if image is None:
            register_error("Failed to load image", filename)
            return
        
    with nvtx.annotate("Process VIO", color="green"):
        try:
            result_vio = odometry.add_trace_pt(image, data)
            if 'lat' not in result_vio or 'lon' not in result_vio:
                register_error("VIO result missing 'lat' or 'lon'", filename)
                return

            with lock:
                lat_VIO.append(result_vio['lat'])
                lon_VIO.append(result_vio['lon'])
                alt_VIO.append(data['VIO']['alt'])
        except Exception as e:
            register_error("VIO processing error", filename)
            return

    with nvtx.annotate("Process GPS", color="orange"):
        try:
            with lock:
                lat_GPS.append(data['GNRMC'].get('lat', 0.0))
                lon_GPS.append(data['GNRMC'].get('lon', 0.0))
                alt_GPS.append(data['GPS_RAW_INT']['alt'])
        except KeyError:
            register_error("GPS data missing", filename)

"""
Путем перебора наибольшая выгода при 6 потоках
"""

def main():
  workers = 6
  with nvtx.annotate("ThreadPool Execution", color="purple"):
    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:
      executor.map(process_file, json_files[start:start + count_json])
  
  # Вывод отчетности
  with nvtx.annotate("Report Errors", color="pink"):
    print("\nError Report:")
    for error_type, error_info in fails_collect.items():
      print(f"{error_type} - {error_info['num']} occurrences")
      print(f"Files: {', '.join(error_info['files'])}")
      print()
  
  with nvtx.annotate("Write Debug Points", color="gray"):
    with open("Debugs/debug_points.txt", "w") as f:
      f.write("")
      for i in range(len(lat_GPS)):
        f.write(f'Point num {i}\n')
        f.write(f'{i} point GPS lat: {lat_GPS[i]}\n')
        f.write(f'{i} point VIO lat: {lat_VIO[i]}\n')
        f.write(f'{i} point GPS lon: {lon_GPS[i]}\n')
        f.write(f'{i} point VIO lon: {lon_VIO[i]}\n')

with nvtx.annotate("Main Function", color="darkviolet"):
    main()

print(len(lat_GPS))
print(len(lat_VIO))

# Шаг 1. Загрузка координат
gps_lat = lat_GPS.copy()
gps_lon = lon_GPS.copy()
vio_lat = lat_VIO.copy()
vio_lon = lon_VIO.copy()
gps_alt = alt_GPS.copy()
vio_alt = alt_VIO.copy()

# Шаг 2. Сохраняем начальные точки (они должны совпадать)
gps_lon0 = gps_lon[0]
gps_lat0 = gps_lat[0]
vio_lon0 = vio_lon[0]
vio_lat0 = vio_lat[0]

# Шаг 3. Вычисляем средние изменения (дельты) для последовательностей координат
mean_gps_lon_diff = sum(abs(gps_lon[i + 1] - gps_lon[i]) for i in range(len(gps_lon) - 1)) / (len(gps_lon) - 1)
mean_gps_lat_diff = sum(abs(gps_lat[i + 1] - gps_lat[i]) for i in range(len(gps_lat) - 1)) / (len(gps_lat) - 1)

mean_vio_lon_diff = sum(abs(vio_lon[i + 1] - vio_lon[i]) for i in range(len(vio_lon) - 1)) / (len(vio_lon) - 1)
mean_vio_lat_diff = sum(abs(vio_lat[i + 1] - vio_lat[i]) for i in range(len(vio_lat) - 1)) / (len(vio_lat) - 1)


# Шаг 4. Вычисляем масштабные коэффициенты
# Здесь предположено, что оси VIO перепутаны:
# - GPS долгота (горизонталь) соответствует VIO "широте" (vio_lat)
# - GPS широта (вертикаль) соответствует VIO "долготе" (vio_lon)
scale_for_lon = mean_gps_lon_diff / mean_vio_lat_diff  # Для преобразования VIO широты -> GPS долгота
scale_for_lat = mean_gps_lat_diff / mean_vio_lon_diff  # Для преобразования VIO долготы -> GPS широта


# Шаг 5. Сохраняем параметры трансформации в JSON
transformation_params = {
    "gps_lon0": gps_lon0,
    "gps_lat0": gps_lat0,
    "vio_lon0": vio_lon0,
    "vio_lat0": vio_lat0,
    "scale_for_lon": scale_for_lon,
    "scale_for_lat": scale_for_lat
}

with open("Debugs/transformation_params.json", "w") as f:
    json.dump(transformation_params, f, indent=4)

# Шаг 6. Определяем функцию для преобразования VIO координат с использованием сохранённых параметров
def transform_vio_coords(vio_lon_list, vio_lat_list, params):
    """
    Преобразование координат VIO по сохранённым параметрам.
    Аргументы:
        vio_lon_list: список VIO долготы (будет использоваться для расчёта GPS широты)
        vio_lat_list: список VIO широты (будет использоваться для расчёта GPS долготы)
        params: словарь с параметрами трансформации
    Возвращает:
        transformed_lon: список преобразованных GPS долготы
        transformed_lat: список преобразованных GPS широты
    """
    gps_lon0 = params["gps_lon0"]
    gps_lat0 = params["gps_lat0"]
    vio_lon0 = params["vio_lon0"]
    vio_lat0 = params["vio_lat0"]
    scale_for_lon = params["scale_for_lon"]
    scale_for_lat = params["scale_for_lat"]

    # Преобразование:
    # Для GPS долготы используем VIO широту, сдвигаем и масштабируем:
    transformed_lon = [(v_lat - vio_lat0) * scale_for_lon + gps_lon0 for v_lat in vio_lat_list]
    # Для GPS широты используем VIO долготу, но с инверсией (так как ось перевёрнута):
    transformed_lat = [-(v_lon - vio_lon0) * scale_for_lat + gps_lat0 for v_lon in vio_lon_list]
    return transformed_lon, transformed_lat

# Применяем трансформацию к имеющимся данным (для демонстрации)
vio_lon_transformed, vio_lat_transformed = transform_vio_coords(vio_lon, vio_lat, transformation_params)

# Преобразуем высоту VIO в метры (делим на 10, так как в VIO высота в дециметрах)
vio_alt_meters = [v_alt * 1000 for v_alt in vio_alt]

# Создаем несколько графиков с разными углами обзора
fig = plt.figure(figsize=(18, 14))

# Первый график — угол 30 по вертикали и 60 по горизонтали
ax1 = fig.add_subplot(231, projection='3d')
ax1.plot(gps_lon, gps_lat, gps_alt, linestyle="-", color="blue", label="GPS")
ax1.plot(vio_lon_transformed, vio_lat_transformed, vio_alt_meters, linestyle="--", color="red", label="VIO (трансформированные)")
ax1.set_xlabel('Долгота', fontsize=10)  # Уменьшаем размер шрифта
ax1.set_ylabel('Широта', fontsize=10)
ax1.set_title('Вид 1: 90° по вертикали, -90° по горизонтали', fontsize=12)
ax1.view_init(elev=90, azim=-90)
ax1.legend()
ax1.tick_params(axis='both', which='major', labelsize=8)  # Уменьшаем размер меток осей

# Второй график — угол 45 по вертикали и 90 по горизонтали
ax2 = fig.add_subplot(232, projection='3d')
ax2.plot(gps_lon, gps_lat, gps_alt, linestyle="-", color="blue", label="GPS")
ax2.plot(vio_lon_transformed, vio_lat_transformed, vio_alt_meters, linestyle="--", color="red", label="VIO (трансформированные)")
ax2.set_xlabel('Долгота', fontsize=10)
ax2.set_zlabel('Высота (метры)', fontsize=10)
ax2.set_title('Вид 2: 0° по вертикали, 90° по горизонтали', fontsize=12)
ax2.view_init(elev=0, azim=-90)
ax2.legend()
ax2.tick_params(axis='both', which='major', labelsize=8)

# Третий график — угол 60 по вертикали и 180 по горизонтали
ax3 = fig.add_subplot(233, projection='3d')
ax3.plot(gps_lon, gps_lat, gps_alt, linestyle="-", color="blue", label="GPS")
ax3.plot(vio_lon_transformed, vio_lat_transformed, vio_alt_meters, linestyle="--", color="red", label="VIO (трансформированные)")
ax3.set_xlabel('Долгота', fontsize=10)
ax3.set_ylabel('Широта', fontsize=10)
ax3.set_zlabel('Высота (метры)', fontsize=10)
ax3.set_title('Вид 3: 60° по вертикали, 180° по горизонтали', fontsize=12)
ax3.view_init(elev=60, azim=180)
ax3.legend()
ax3.tick_params(axis='both', which='major', labelsize=8)

# Автоматически подгоняем графики по размеру
plt.tight_layout()

# Скрываем метки оси
ax1.set_zticks([])
ax1.set_zticklabels([])

# Скрываем метки оси
ax2.set_yticks([])
ax2.set_yticklabels([])

# Показать графики
plt.show()


draw_cinema = False

if draw_cinema:
    lat = vio_lat
    lon = vio_lon
    alt = vio_alt

    step = 1

    # Создание фигуры с анимацией
    fig = go.Figure()

    # Добавление начального состояния
    fig.add_trace(go.Scatter3d(
        x=[lat[0]],
        y=[lon[0]],
        z=[alt[0]],
        mode='lines+markers',
        line=dict(color='blue', width=2),
        marker=dict(size=4, color=alt[0], colorscale='Viridis')
    ))

    # Создание кадров анимации
    frames = []
    for i in range(1, len(lat)):
        frame = go.Frame(
            data=[go.Scatter3d(
                x=lat[:i+step],  # Данные до текущего кадра
                y=lon[:i+step],
                z=alt[:i+step],
                mode='lines+markers',
                line=dict(color='blue', width=2),
                marker=dict(size=4, color=alt[:i+step], colorscale='Viridis')
            )]
        )
        frames.append(frame)

    fig.frames = frames

    # Добавление кнопок управления анимацией
    fig.update_layout(
        updatemenus=[{
            'buttons': [
                {
                    'args': [None, {'frame': {'duration': 50, 'redraw': True}, 'fromcurrent': True}],
                    'label': 'Старт',
                    'method': 'animate'
                },
                {
                    'args': [[None], {'frame': {'duration': 0, 'redraw': True}, 'mode': 'immediate', 'transition': {'duration': 0}}],
                    'label': 'Стоп',
                    'method': 'animate'
                }
            ],
            'direction': 'left',
            'pad': {'r': 10, 't': 87},
            'showactive': False,
            'type': 'buttons',
            'x': 0.1,
            'xanchor': 'right',
            'y': 0,
            'yanchor': 'top'
        }]
    )

    # Настройка размеров и осей
    fig.update_layout(
        scene=dict(
            xaxis_title='Широта',
            yaxis_title='Долгота',
            zaxis_title='Высота',
        ),
        title='Анимация маршрута дрона',
        width=1200,
        height=800,
    )

    fig.show()


================================================
File: Calibrate/calibrate.py
================================================
# %%
import nvtx
import vio_ort
import matplotlib.pyplot as plt
import os
import json
import cv2
import concurrent.futures
import threading
from collections import defaultdict
import plotly.graph_objects as go

# %%
with nvtx.annotate("Initialize VIO and Parameters", color="blue"):
    odometry = vio_ort.VIO(lat0=54.889668, lon0=83.1258973333, alt0=0)

    set_dir = '2024_12_15_15_31_8_num_3'

    json_files = [f for f in os.listdir(set_dir) if f.endswith('.json')]
    json_files.sort()

    start = 0
    count_json = len(json_files)

    lat_VIO, lon_VIO = [], []
    lat_GPS, lon_GPS = [], []
    alt_VIO, alt_GPS = [], []

# %%
with nvtx.annotate("Initialize Error Collection", color="red"):
    fails_collect = defaultdict(lambda: {'num': 0, 'files': []})
    lock = threading.Lock()

# %%
@nvtx.annotate("Register Error", color="red")
def register_error(error_type, filename):
    with lock:
        fails_collect[error_type]['num'] += 1
        fails_collect[error_type]['files'].append(filename)

# %%
@nvtx.annotate("Process File", color="blue")
def process_file(filename):
    with nvtx.annotate("Load JSON", color="cyan"):
        try:
            with open(os.path.join(set_dir, filename), 'r') as file:
                data = json.load(file)
        except json.JSONDecodeError:
            register_error("JSON decode error", filename)
            return
        except Exception:
            register_error("Processing error", filename)
            return

    with nvtx.annotate("Validate Data", color="magenta"):
        if 'GNRMC' not in data or 'VIO' not in data:
            register_error("Missing GNRMC or VIO", filename)
            return
        if data['GNRMC'].get('status') != 'A':
            register_error("GNRMC status not 'A'", filename)
            return

    with nvtx.annotate("Load Image", color="yellow"):
        img_path = os.path.join(set_dir, os.path.splitext(filename)[0] + '.jpg')
        if not os.path.exists(img_path):
            register_error("Image not found", filename)
            return
        image = cv2.imread(img_path)
        if image is None:
            register_error("Failed to load image", filename)
            return

    with nvtx.annotate("Process VIO", color="green"):
        try:
            result_vio = odometry.add_trace_pt(image, data)
            if 'lat' not in result_vio or 'lon' not in result_vio:
                register_error("VIO result missing 'lat' or 'lon'", filename)
                return
            with lock:
                lat_VIO.append(result_vio['lat'])
                lon_VIO.append(result_vio['lon'])
                alt_VIO.append(data['VIO']['alt'])
        except Exception as e:
            register_error("VIO processing error", filename)
            return

    with nvtx.annotate("Process GPS", color="orange"):
        try:
            with lock:
                lat_GPS.append(data['GNRMC'].get('lat', 0.0))
                lon_GPS.append(data['GNRMC'].get('lon', 0.0))
                alt_GPS.append(data['GPS_RAW_INT']['alt'])
        except KeyError:
            register_error("GPS data missing", filename)

# %%
@nvtx.annotate("Main Function Execution", color="darkviolet")
def main():
    workers = 6
    with nvtx.annotate("ThreadPool Execution", color="purple"):
        with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:
            executor.map(process_file, json_files[start:start + count_json])

    with nvtx.annotate("Error Reporting", color="pink"):
        print("\nError Report:")
        for error_type, error_info in fails_collect.items():
            print(f"{error_type} - {error_info['num']} occurrences")
            print(f"Files: {', '.join(error_info['files'])}")
            print()

    with nvtx.annotate("Write Debug Points", color="gray"):
        with open("Debugs/debug_points.txt", "w") as f:
            for i in range(len(lat_GPS)):
                f.write(f'Point num {i}\n')
                f.write(f'{i} point GPS lat: {lat_GPS[i]}\n')
                f.write(f'{i} point VIO lat: {lat_VIO[i]}\n')
                f.write(f'{i} point GPS lon: {lon_GPS[i]}\n')
                f.write(f'{i} point VIO lon: {lon_VIO[i]}\n')

# %%
with nvtx.annotate("Main Script Execution", color="darkgreen"):
    main()

# %%
with nvtx.annotate("Coordinate Transformation", color="gold"):
    gps_lat = lat_GPS.copy()
    gps_lon = lon_GPS.copy()
    vio_lat = lat_VIO.copy()
    vio_lon = lon_VIO.copy()
    gps_alt = alt_GPS.copy()
    vio_alt = alt_VIO.copy()

    gps_lon0, gps_lat0 = gps_lon[0], gps_lat[0]
    vio_lon0, vio_lat0 = vio_lon[0], vio_lat[0]

    mean_gps_lon_diff = sum(abs(gps_lon[i + 1] - gps_lon[i]) for i in range(len(gps_lon) - 1)) / (len(gps_lon) - 1)
    mean_gps_lat_diff = sum(abs(gps_lat[i + 1] - gps_lat[i]) for i in range(len(gps_lat) - 1)) / (len(gps_lat) - 1)
    mean_vio_lon_diff = sum(abs(vio_lon[i + 1] - vio_lon[i]) for i in range(len(vio_lon) - 1)) / (len(vio_lon) - 1)
    mean_vio_lat_diff = sum(abs(vio_lat[i + 1] - vio_lat[i]) for i in range(len(vio_lat) - 1)) / (len(vio_lat) - 1)

    scale_for_lon = mean_gps_lon_diff / mean_vio_lat_diff
    scale_for_lat = mean_gps_lat_diff / mean_vio_lon_diff

    transformation_params = {
        "gps_lon0": gps_lon0,
        "gps_lat0": gps_lat0,
        "vio_lon0": vio_lon0,
        "vio_lat0": vio_lat0,
        "scale_for_lon": scale_for_lon,
        "scale_for_lat": scale_for_lat
    }

    with open("Debugs/transformation_params.json", "w") as f:
        json.dump(transformation_params, f, indent=4)

# %%
# Шаг 6. Определяем функцию для преобразования VIO координат с использованием сохранённых параметров
def transform_vio_coords(vio_lon_list, vio_lat_list, params):
    """
    Преобразование координат VIO по сохранённым параметрам.
    Аргументы:
        vio_lon_list: список VIO долготы (будет использоваться для расчёта GPS широты)
        vio_lat_list: список VIO широты (будет использоваться для расчёта GPS долготы)
        params: словарь с параметрами трансформации
    Возвращает:
        transformed_lon: список преобразованных GPS долготы
        transformed_lat: список преобразованных GPS широты
    """
    gps_lon0 = params["gps_lon0"]
    gps_lat0 = params["gps_lat0"]
    vio_lon0 = params["vio_lon0"]
    vio_lat0 = params["vio_lat0"]
    scale_for_lon = params["scale_for_lon"]
    scale_for_lat = params["scale_for_lat"]

    # Преобразование:
    # Для GPS долготы используем VIO широту, сдвигаем и масштабируем:
    transformed_lon = [(v_lat - vio_lat0) * scale_for_lon + gps_lon0 for v_lat in vio_lat_list]
    # Для GPS широты используем VIO долготу, но с инверсией (так как ось перевёрнута):
    transformed_lat = [-(v_lon - vio_lon0) * scale_for_lat + gps_lat0 for v_lon in vio_lon_list]
    return transformed_lon, transformed_lat

# Применяем трансформацию к имеющимся данным (для демонстрации)
vio_lon_transformed, vio_lat_transformed = transform_vio_coords(vio_lon, vio_lat, transformation_params)

# Преобразуем высоту VIO в метры (делим на 10, так как в VIO высота в дециметрах)
vio_alt_meters = [v_alt * 1000 for v_alt in vio_alt]

# %%
# Создаем несколько графиков с разными углами обзора
fig = plt.figure(figsize=(18, 14))

# Первый график — угол 30 по вертикали и 60 по горизонтали
ax1 = fig.add_subplot(231, projection='3d')
ax1.plot(gps_lon, gps_lat, gps_alt, linestyle="-", color="blue", label="GPS")
ax1.plot(vio_lon_transformed, vio_lat_transformed, vio_alt_meters, linestyle="--", color="red", label="VIO (трансформированные)")
ax1.set_xlabel('Долгота', fontsize=10)  # Уменьшаем размер шрифта
ax1.set_ylabel('Широта', fontsize=10)
ax1.set_title('Вид 1: 90° по вертикали, -90° по горизонтали', fontsize=12)
ax1.view_init(elev=90, azim=-90)
ax1.legend()
ax1.tick_params(axis='both', which='major', labelsize=8)  # Уменьшаем размер меток осей

# Второй график — угол 45 по вертикали и 90 по горизонтали
ax2 = fig.add_subplot(232, projection='3d')
ax2.plot(gps_lon, gps_lat, gps_alt, linestyle="-", color="blue", label="GPS")
ax2.plot(vio_lon_transformed, vio_lat_transformed, vio_alt_meters, linestyle="--", color="red", label="VIO (трансформированные)")
ax2.set_xlabel('Долгота', fontsize=10)
ax2.set_zlabel('Высота (метры)', fontsize=10)
ax2.set_title('Вид 2: 0° по вертикали, 90° по горизонтали', fontsize=12)
ax2.view_init(elev=0, azim=-90)
ax2.legend()
ax2.tick_params(axis='both', which='major', labelsize=8)

# Третий график — угол 60 по вертикали и 180 по горизонтали
ax3 = fig.add_subplot(233, projection='3d')
ax3.plot(gps_lon, gps_lat, gps_alt, linestyle="-", color="blue", label="GPS")
ax3.plot(vio_lon_transformed, vio_lat_transformed, vio_alt_meters, linestyle="--", color="red", label="VIO (трансформированные)")
ax3.set_xlabel('Долгота', fontsize=10)
ax3.set_ylabel('Широта', fontsize=10)
ax3.set_zlabel('Высота (метры)', fontsize=10)
ax3.set_title('Вид 3: 60° по вертикали, 180° по горизонтали', fontsize=12)
ax3.view_init(elev=60, azim=180)
ax3.legend()
ax3.tick_params(axis='both', which='major', labelsize=8)

# Автоматически подгоняем графики по размеру
plt.tight_layout()

# Скрываем метки оси
ax1.set_zticks([])
ax1.set_zticklabels([])

# Скрываем метки оси
ax2.set_yticks([])
ax2.set_yticklabels([])

# Показать графики
plt.show()


# %%
draw_cinema = False

# %%
if draw_cinema:
    lat = vio_lat
    lon = vio_lon
    alt = vio_alt

    step = 1

    # Создание фигуры с анимацией
    fig = go.Figure()

    # Добавление начального состояния
    fig.add_trace(go.Scatter3d(
        x=[lat[0]],
        y=[lon[0]],
        z=[alt[0]],
        mode='lines+markers',
        line=dict(color='blue', width=2),
        marker=dict(size=4, color=alt[0], colorscale='Viridis')
    ))

    # Создание кадров анимации
    frames = []
    for i in range(1, len(lat)):
        frame = go.Frame(
            data=[go.Scatter3d(
                x=lat[:i+step],  # Данные до текущего кадра
                y=lon[:i+step],
                z=alt[:i+step],
                mode='lines+markers',
                line=dict(color='blue', width=2),
                marker=dict(size=4, color=alt[:i+step], colorscale='Viridis')
            )]
        )
        frames.append(frame)

    fig.frames = frames

    # Добавление кнопок управления анимацией
    fig.update_layout(
        updatemenus=[{
            'buttons': [
                {
                    'args': [None, {'frame': {'duration': 50, 'redraw': True}, 'fromcurrent': True}],
                    'label': 'Старт',
                    'method': 'animate'
                },
                {
                    'args': [[None], {'frame': {'duration': 0, 'redraw': True}, 'mode': 'immediate', 'transition': {'duration': 0}}],
                    'label': 'Стоп',
                    'method': 'animate'
                }
            ],
            'direction': 'left',
            'pad': {'r': 10, 't': 87},
            'showactive': False,
            'type': 'buttons',
            'x': 0.1,
            'xanchor': 'right',
            'y': 0,
            'yanchor': 'top'
        }]
    )

    # Настройка размеров и осей
    fig.update_layout(
        scene=dict(
            xaxis_title='Широта',
            yaxis_title='Долгота',
            zaxis_title='Высота',
        ),
        title='Анимация маршрута дрона',
        width=1200,
        height=800,
    )

    fig.show()

================================================
File: Calibrate/vio_ort.py
================================================
import json
from time import time
from datetime import datetime, date, timedelta

import numpy as np
import cv2
from PIL import Image

from modules.xfeat_ort import XFeat

from pymavlink import mavutil

import nvtx


# Загрузка параметров камеры
with nvtx.annotate("Load Camera Parameters", color="darkgreen"):
    with open('fisheye_2024-09-18.json') as f:
        camparam = json.load(f)

    MASK = None
    for shape in camparam['shapes']:
        if shape['label'] == 'mask':
            with nvtx.annotate("Create Camera Mask", color="purple"):
                MASK = np.zeros((camparam['imageHeight'], camparam['imageWidth'], 3), dtype=np.uint8)
                cnt = np.asarray(shape['points']).reshape(-1, 1, 2).astype(np.int32)
                cv2.drawContours(MASK, [cnt], -1, (255, 255, 255), -1)

    with nvtx.annotate("Initialize Camera Constants", color="brown"):
        CENTER = [camparam['ppx'], camparam['ppy']]
        CENTER[0] += -6  # TODO: insert corrections into file
        CENTER[1] += 26  # TODO: insert corrections into file
        FOCAL = camparam['focal']
        RAD = camparam['radius']
        CROP_CENTER = np.asarray([RAD / 2, RAD / 2])


# Константы
HOMO_THR = 2.0
NUM_MATCH_THR = 8
TRACE_DEPTH = 4
VEL_FIT_DEPTH = TRACE_DEPTH
METERS_DEG = 111320

FLAGS = mavutil.mavlink.GPS_INPUT_IGNORE_FLAG_VEL_VERT | mavutil.mavlink.GPS_INPUT_IGNORE_FLAG_VERTICAL_ACCURACY | mavutil.mavlink.GPS_INPUT_IGNORE_FLAG_HORIZONTAL_ACCURACY

class VIO():
    
    def __init__(self, lat0=0, lon0=0, alt0=0, top_k=512, detection_threshold=0.05):
        self.lat0 = lat0
        self.lon0 = lon0
        self._matcher = XFeat(top_k=top_k, detection_threshold=detection_threshold)
        self.track = []
        self.trace = []
        self.prev = None
        self.HoM = None
        
    @nvtx.annotate("VIO.add_trace_pt", color="blue")
    def add_trace_pt(self, frame, msg):
        
        # Получаем углы и высоту – можно обернуть в отдельный NVTX-блок
        
        with nvtx.annotate("Fetch Angles & Height", color="green"):
            angles = fetch_angles(msg)
            height = fetch_height(msg)
            timestamp = time()
        
        with nvtx.annotate("Preprocess Frame", color="yellow"):
            frame = preprocess_frame(frame, MASK)

        with nvtx.annotate("Rotate Image", color="orange"):
            roll, pitch = angles['roll'] / np.pi * 180, angles['pitch'] / np.pi * 180
            dpp = (int(CENTER[0] + roll * 2.5),
                   int(CENTER[1] + pitch * 2.5))
            rotated = Image.fromarray(frame).rotate(angles['yaw']/np.pi*180, center=dpp)
            rotated = np.asarray(rotated)

        # Здесь можно добавить аннотацию для remapping и дальнейшей обработки
        with nvtx.annotate("Remap and Crop", color="cyan"):
            map_x, map_y = fisheye2rectilinear(FOCAL, dpp, RAD, RAD)
            crop = cv2.remap(rotated, map_x, map_y, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)
        
        # Далее обработка трассы, расчёт позиции и т.д.
        with nvtx.annotate("Detect and compute", color="red"):
            trace_pt = dict(crop=crop,
                            out=self.detect_and_compute(crop),
                            angles=angles,
                            height=height)
        
        if len(self.trace)>TRACE_DEPTH:
            self.trace = self.trace[1:]

        # Например, аннотировать расчёт локальной позиции:
        with nvtx.annotate("Calculate Local Position", color="magenta"):
            if len(self.trace) == 0:
                trace_pt['local_posm'] = np.asarray([0, 0])
            else:
                local_pos_metric = self.calc_pos(trace_pt)
                if local_pos_metric is None:
                    trace_pt['local_posm'] = self.trace[-1]['local_posm']
                else:
                    trace_pt['local_posm'] = local_pos_metric
        
        self.trace.append(trace_pt)
        self.track.append(np.hstack((timestamp, trace_pt['local_posm'], height)))

        # Пример расчёта скорости
        with nvtx.annotate("Fit Velocity", color="darkorange"):
            ts, tn, te, he = np.asarray(self.track[-TRACE_DEPTH:]).T
            if len(tn) >= TRACE_DEPTH:
                vn = np.polyfit(ts, tn, 1)[0]
                ve = np.polyfit(ts, te, 1)[0]
                vd = 0
            else:
                vn, ve, vd = 0, 0, 0
            
        lat = self.lat0 + tn[-1] / METERS_DEG
        lon = self.lon0 + te[-1] / 111320 / np.cos(self.lat0/180*np.pi) # used lat0 to avoid problems with wrong calculated latitude 
        alt = he[-1]
        GPS_week, GPS_ms = calc_GPS_week_time()
        
        return dict(timestamp=float(ts[-1]),
                    to_north=float(tn[-1]),
                    to_east=float(te[-1]),
                    lat=float(lat),
                    lon=float(lon),
                    alt=float(alt),
                    veln=float(vn),
                    vele=float(ve),
                    veld=float(vd),
                    GPS_week=int(GPS_week),
                    GPS_ms=int(GPS_ms)
                    )
    
    def calc_pos(self, next_pt):
        poses = []
        for prev_pt in self.trace:
            match_prev, match_next, HoM = self.match_points_hom(prev_pt['out'],
            next_pt['out'],)

            if len(match_prev) <= NUM_MATCH_THR:
                continue
            
            center_proj = cv2.perspectiveTransform(CROP_CENTER.reshape(-1,1,2), HoM).ravel()
            pix_shift = CROP_CENTER - center_proj
            pix_shift[0], pix_shift[1] = -pix_shift[1], pix_shift[0]
            height = np.mean([prev_pt['height'], next_pt['height']])
            metric_shift = pix_shift / FOCAL * height
            local_pos = prev_pt['local_posm'] + metric_shift
            poses.append(local_pos)

        if len(poses):
            return np.mean(poses, axis=0)
        else:
            return None
    
    def match_points_hom(self, out0, out1):
        idxs0, idxs1 = self._matcher.match(out0['descriptors'], out1['descriptors'], min_cossim=-1 )
        mkpts_0 = out0['keypoints'][idxs0].numpy()
        mkpts_1 = out1['keypoints'][idxs1].numpy()
        
        good_prev = []
        good_next = []
        if len(mkpts_0) >= NUM_MATCH_THR:
            HoM, mask = cv2.findHomography(mkpts_0, mkpts_1, cv2.RANSAC, HOMO_THR)

            mask = mask.ravel().astype(bool)

            good_prev = mkpts_0[mask]
            good_next = mkpts_1[mask]
            return good_prev, good_next, HoM
        else:
            return [], [], np.eye(3)

    def detect_and_compute(self, frame):
        img = self._matcher.parse_input(frame)
        out = self._matcher.detectAndCompute(img)[0]
        return out

    def vio2pixhawk(self, msg):

        viom = msg['VIO']
        
        return  [int(viom['timestamp']*10**6), # Timestamp (micros since boot or Unix epoch)
                0, # GPS sensor id in th, e case of multiple GPS
                FLAGS, # flags to ignore 8, 16, 32 etc
                # (mavutil.mavlink.GPS_INPUT_IGNORE_FLAG_VEL_HORIZ |
                # mavutil.mavlink.GPS_INPUT_IGNORE_FLAG_VEL_VERT |
                # mavutil.mavlink.GPS_INPUT_IGNORE_FLAG_SPEED_ACCURACY) |
                # mavutil.mavlink.GPS_INPUT_IGNORE_FLAG_HORIZONTAL_ACCURACY |
                # mavutil.mavlink.GPS_INPUT_IGNORE_FLAG_VERTICAL_ACCURACY,
                
                viom['GPS_ms'], # GPS time (milliseconds from start of GPS week)
                viom['GPS_week'], # GPS week number
                3, # 0-1: no fix, 2: 2D fix, 3: 3D fix. 4: 3D with DGPS. 5: 3D with RTK
                int(viom['lat']*10**7), # Latitude (WGS84), in degrees * 1E7
                int(viom['lon']*10**7), # Longitude (WGS84), in degrees * 1E7
                viom['alt'], # Altitude (AMSL, not WGS84), in m (positive for up)
                1.0, # GPS HDOP horizontal dilution of precision in m
                1.0, # GPS VDOP vertical dilution of precision in m
                viom['veln'], # GPS velocity in m/s in NORTH direction in earth-fixed NED frame
                viom['vele'], # GPS velocity in m/s in EAST direction in earth-fixed NED frame
                viom['veld'], # GPS velocity in m/s in DOWN direction in earth-fixed NED frame
                0.6, # GPS speed accuracy in m/s
                5.0, # GPS horizontal accuracy in m
                3.0, # GPS vertical accuracy in m
                10, # Number of satellites visible,
                ]

def calc_GPS_week_time():
    today = date.today()
    now = datetime.now()
    epoch = date(1980, 1, 6)
    
    epochMonday = epoch - timedelta(epoch.weekday())
    todayMonday = today - timedelta(today.weekday())
    GPS_week = int((todayMonday - epochMonday).days / 7)
    GPS_ms = ((today - todayMonday).days * 24 + now.hour) * 3600000 + now.minute*60000 + now.second*1000 + int(now.microsecond/1000)
    return GPS_week, GPS_ms

def fetch_angles(msg):
    angles = msg['ATTITUDE']
    #angles = msg['EXT_IMU']
    angles['yaw'] = -angles['yaw']
    return angles

def fetch_height(msg):
    return max(0, msg['AHRS2']['altitude'])
        
def extract_neighborhood(image, keypoint, size):
    x, y = keypoint
    half_size = size // 2
    
    x_start = x - half_size
    x_end = x + half_size
    y_start = y - half_size
    y_end = y + half_size
    # Reject keypoints too close to boundaries
    if x_start<0 or x_end>image.shape[1] or y_start<0 or y_end>image.shape[0]:
        return None
        
    nbh = image[y_start:y_end, x_start:x_end]
    # Reject keypoints  with mask pixels
    if np.any(nbh==0):
        return None
    else:
        return nbh

def fisheye2rectilinear(focal, pp, rw, rh, fproj='equidistant'):
    # Create a grid for the rectilinear image
    rx, ry = np.meshgrid(np.arange(rw) - rw // 2, np.arange(rh) - rh // 2)
    r = np.sqrt(rx**2 + ry**2) / focal

    angle_n = np.arctan(r)
    if fproj == 'equidistant':
        angle_n = angle_n
    elif fproj == 'orthographic':
        angle_n = np.sin(angle_n)    
    elif fproj == 'stereographic':
        angle_n = 2*np.tan(angle_n/2)
    elif fproj == 'equisolid':
        angle_n = 2*np.sin(angle_n/2)
    
    angle_t = np.arctan2(ry, rx)
    
    pt_x = focal * angle_n * np.cos(angle_t) + pp[0]
    pt_y = focal * angle_n * np.sin(angle_t) + pp[1]
    
    map_x = pt_x.astype(np.float32)
    map_y = pt_y.astype(np.float32)
    
    return map_x, map_y

def preprocess_frame(frame, mask):
    frame = np.where(mask, frame, 0)
    return frame